# Implementation Plan: Phase 5 Microservices Platform

**Branch**: `002-microservices-dapr-kafka` | **Date**: 2026-02-08 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/002-microservices-dapr-kafka/spec.md`

## Summary

Phase 5 decomposes the AI-Native Todo Chatbot into five event-driven
microservices (Todo, Audit, WebSocket, Notification, Recurring Task) that
communicate exclusively via Dapr sidecars using Kafka (Redpanda) as the
Pub/Sub broker. All services are Python/FastAPI with async PostgreSQL
(SQLAlchemy 2.0 + asyncpg) on Neon DB. Local deployment targets Minikube;
cloud deployment targets AKS/GKE.

## Technical Context

**Language/Version**: Python 3.11+
**Primary Dependencies**: FastAPI, Dapr SDK 1.16.0, SQLAlchemy 2.0 (async),
  asyncpg, Pydantic v2, uvicorn, APScheduler
**Storage**: PostgreSQL (Neon DB) — per-service schema isolation
**Event Broker**: Kafka via Redpanda (single-node, ~1GB RAM)
**Distributed Runtime**: Dapr 1.14+ (Pub/Sub, State, Secrets)
**Testing**: pytest, pytest-asyncio, httpx (async test client)
**Target Platform**: Minikube (local), AKS/GKE (cloud)
**Project Type**: Microservices monorepo (5 services + shared library)
**Performance Goals**: Event delivery <1s, WebSocket broadcast <2s, health
  checks pass within 60s of deployment
**Constraints**: ~3.7GB Docker Desktop memory, Dapr Jobs API unavailable in
  Python SDK (using APScheduler instead)
**Scale/Scope**: 5 microservices, 3 Kafka topics, 4 Dapr components, 4 DB
  schemas, 5 API contracts

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

| # | Principle | Status | Evidence |
|---|-----------|--------|----------|
| I | Spec-Driven Development | PASS | All tasks will reference Task IDs; no code without spec |
| II | Dapr-Mediated Communication | PASS | All inter-service communication via Dapr Pub/Sub; no direct HTTP/Kafka |
| III | Event-Driven Architecture | PASS | 3 Kafka topics (task-events, reminders, task-updates) via Dapr |
| IV | Microservices Isolation | PASS | 5 independent services with per-service DB schemas |
| V | Secrets Governance | PASS | Dapr Secrets API + K8s Secrets; no hardcoded credentials |
| VI | Phase 4 Immutability | PASS | Phase 5 code in `services/` directory; Phase 4 untouched |
| VII | Container-First Deployment | PASS | Each service has own Dockerfile; Minikube + AKS/GKE |
| VIII | Fail-Fast Validation | PASS | GitHub Actions CI/CD; startup probes for Dapr/Kafka/DB |
| IX | Observability & Traceability | PASS | JSON structured logs with task_id field; health endpoints |

**Post-design re-check**: Constitution Check re-evaluated after Phase 1 design.
One deviation noted — Dapr Jobs API unavailable in Python SDK. Using APScheduler
as alternative. This does NOT violate Principle II (Dapr-Mediated Communication)
because APScheduler runs within the Recurring Task Service process and still
publishes events via Dapr Pub/Sub. Only the scheduling trigger mechanism is
internal. Documented in Complexity Tracking below.

## Project Structure

### Documentation (this feature)

```text
specs/002-microservices-dapr-kafka/
├── plan.md              # This file
├── spec.md              # Feature specification
├── research.md          # Technology research and decisions
├── data-model.md        # Entity definitions and schemas
├── quickstart.md        # Local deployment guide
├── contracts/           # OpenAPI specs per service
│   ├── todo-service-api.yaml
│   ├── audit-service-api.yaml
│   ├── websocket-service-api.yaml
│   ├── notification-service-api.yaml
│   └── recurring-task-service-api.yaml
├── checklists/
│   └── requirements.md  # Spec quality checklist
└── tasks.md             # Generated by /sp.tasks
```

### Source Code (repository root)

```text
services/
├── shared/                          # Shared library
│   ├── pyproject.toml
│   └── shared/
│       ├── __init__.py
│       ├── events.py                # Event schema definitions (Pydantic)
│       ├── dapr_helpers.py          # Dapr client wrapper utilities
│       ├── logging.py               # Structured JSON logger with task_id
│       ├── config.py                # Base config (Dapr, DB connection)
│       └── health.py                # Common health check endpoints
├── todo-service/
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py                  # FastAPI app + Dapr setup
│   │   ├── config.py                # Service-specific settings
│   │   ├── models/
│   │   │   ├── __init__.py
│   │   │   └── task.py              # SQLAlchemy Task model
│   │   ├── schemas/
│   │   │   ├── __init__.py
│   │   │   └── task.py              # Pydantic request/response schemas
│   │   ├── routers/
│   │   │   ├── __init__.py
│   │   │   └── tasks.py             # CRUD API endpoints
│   │   ├── services/
│   │   │   ├── __init__.py
│   │   │   └── task_service.py      # Business logic + event publishing
│   │   └── db/
│   │       ├── __init__.py
│   │       └── session.py           # Async DB session factory
│   ├── tests/
│   │   ├── __init__.py
│   │   ├── test_tasks_api.py        # API endpoint tests
│   │   └── test_task_service.py     # Business logic tests
│   ├── alembic/                     # DB migrations
│   │   ├── alembic.ini
│   │   ├── env.py
│   │   └── versions/
│   ├── requirements.txt
│   └── Dockerfile
├── audit-service/
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py
│   │   ├── config.py
│   │   ├── models/audit_record.py
│   │   ├── schemas/audit_record.py
│   │   ├── routers/audit.py
│   │   ├── services/audit_service.py
│   │   ├── events/handlers.py       # Dapr Pub/Sub subscriber
│   │   └── db/session.py
│   ├── tests/
│   ├── alembic/
│   ├── requirements.txt
│   └── Dockerfile
├── websocket-service/
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py
│   │   ├── config.py
│   │   ├── events/handlers.py       # Dapr Pub/Sub subscriber
│   │   └── ws/manager.py            # WebSocket connection manager
│   ├── tests/
│   ├── requirements.txt
│   └── Dockerfile
├── notification-service/
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py
│   │   ├── config.py
│   │   ├── models/notification.py
│   │   ├── schemas/notification.py
│   │   ├── routers/notifications.py
│   │   ├── services/notification_service.py
│   │   ├── events/handlers.py       # Dapr Pub/Sub subscriber
│   │   └── db/session.py
│   ├── tests/
│   ├── alembic/
│   ├── requirements.txt
│   └── Dockerfile
└── recurring-task-service/
    ├── app/
    │   ├── __init__.py
    │   ├── main.py
    │   ├── config.py
    │   ├── models/recurrence.py
    │   ├── schemas/recurrence.py
    │   ├── routers/schedules.py
    │   ├── services/recurrence_service.py
    │   ├── events/handlers.py        # Dapr Pub/Sub subscriber
    │   ├── scheduler/jobs.py          # APScheduler reminder scheduling
    │   └── db/session.py
    ├── tests/
    ├── alembic/
    ├── requirements.txt
    └── Dockerfile

k8s/
├── deployments/
│   ├── redpanda.yaml                # Redpanda single-node Kafka broker
│   ├── todo-service.yaml            # Deployment + Service + Dapr annotations
│   ├── audit-service.yaml
│   ├── websocket-service.yaml
│   ├── notification-service.yaml
│   └── recurring-task-service.yaml
├── dapr-components/
│   ├── kafka-pubsub.yaml            # pubsub.kafka component
│   ├── statestore.yaml              # state.postgresql component
│   └── kubernetes-secrets.yaml      # secretstores.kubernetes component
└── secrets/
    └── create-secrets.sh            # Script to create K8s secrets

.github/
└── workflows/
    └── ci-cd.yaml                   # GitHub Actions pipeline
```

**Structure Decision**: Microservices monorepo with shared library. Each service
is independently buildable and deployable from its own Dockerfile. The `shared/`
package is installed as a local dependency in each service's `requirements.txt`
via `../shared`. Kubernetes manifests are in `k8s/` (not Helm charts — Dapr
annotations replace much of what Helm templating provided in Phase 4).

## Architecture Decisions

### AD-1: Redpanda over Strimzi for Local Kafka

Redpanda uses ~1GB RAM (C++ single binary) vs Strimzi's 4GB minimum
(JVM + ZooKeeper + Operator). With 3.7GB Docker Desktop budget, Strimzi
is not viable. Redpanda is Kafka protocol-compatible at the wire level.

### AD-2: APScheduler over Dapr Jobs API

Dapr Jobs API has no Python SDK support (only Go/NET). APScheduler provides
equivalent in-process scheduling with asyncio support. The scheduler runs
within the Recurring Task Service and publishes events via Dapr Pub/Sub,
maintaining the Dapr-mediated communication principle for all external calls.

### AD-3: SQLAlchemy 2.0 Async over SQLModel

SQLModel is stuck on SQLAlchemy 1.4.41 (outdated). SQLAlchemy 2.0 provides
native async support, modern API, and asyncpg driver integration for ~5x
performance over psycopg3.

### AD-4: Per-Service PostgreSQL Schema (Not Separate DBs)

Using schemas within a single Neon DB instance instead of separate databases.
This simplifies connection management and stays within Neon's free tier limits
while still enforcing logical data isolation per Constitution Principle IV.

### AD-5: K8s Manifests over Helm Charts for Phase 5 Services

Phase 5 services use plain Kubernetes YAML with Dapr annotations rather than
Helm charts. Dapr annotations replace the parameterization that Helm provided
for probe configs, sidecar injection, and component binding. This is simpler
for 5 services that share the same pattern. Phase 4 Helm charts remain for
Phase 4 infrastructure.

## Event Flow Architecture

```
┌─────────────┐     task-events     ┌──────────────┐
│ Todo Service │────────────────────→│ Audit Service │
│  (port 8001) │                    └──────────────┘
│              │     task-events     ┌──────────────────────┐
│              │────────────────────→│ Recurring Task Service│
│              │                    │  (port 8005)          │
│              │     task-updates    ┌────────────────────┐
│              │────────────────────→│ WebSocket Service   │
└─────────────┘                    │  (port 8003)        │
                                    └────────────────────┘

┌──────────────────────┐  reminders  ┌──────────────────────┐
│ Recurring Task Service│────────────→│ Notification Service │
│  (port 8005)          │            │  (port 8004)          │
└──────────────────────┘            └──────────────────────┘

All arrows flow through: [Service] → [Dapr Sidecar] → [Kafka/Redpanda] → [Dapr Sidecar] → [Consumer Service]
```

## Dapr Component Configuration

| Component | Type | Spec Version | Key Config |
|-----------|------|-------------|------------|
| kafka-pubsub | pubsub.kafka | v1 | brokers: redpanda:9092, authType: none |
| statestore | state.postgresql | v2 | connectionString via K8s secret |
| kubernetes-secrets | secretstores.kubernetes | v1 | Default K8s secret store |

## Port Assignments

| Service | App Port | Dapr HTTP | Dapr gRPC |
|---------|----------|-----------|-----------|
| Todo Service | 8001 | 3501 | 50001 |
| Audit Service | 8002 | 3502 | 50002 |
| WebSocket Service | 8003 | 3503 | 50003 |
| Notification Service | 8004 | 3504 | 50004 |
| Recurring Task Service | 8005 | 3505 | 50005 |
| Redpanda (Kafka) | 9092 | — | — |

## Sequencing & Dependencies

```
Phase 1: Setup
  └── Project structure, shared library, Dapr components, Redpanda deployment
      │
Phase 2: Foundational
  └── DB schemas, async sessions, event schemas, health endpoints, logging
      │
Phase 3: Todo Service (P1) ← Must be first (all events originate here)
  └── CRUD API → event publishing → Dapr Pub/Sub integration
      │
Phase 4: Audit Service (P2) ← Simplest consumer, validates pipeline
  └── Subscribe task-events → store audit records → query API
      │
Phase 5: WebSocket Service (P3) ← Validates task-updates topic
  └── Subscribe task-updates → WebSocket broadcast → connection management
      │
Phase 6: Notification Service (P4) ← Validates reminders topic
  └── Subscribe reminders → in-app notification delivery
      │
Phase 7: Recurring Task Service (P5) ← Most complex, APScheduler
  └── Subscribe task-events → detect completions → schedule next occurrence
      │
Phase 8: Deployment & CI/CD
  └── K8s manifests, Minikube deployment, GitHub Actions pipeline
      │
Phase 9: Polish & Validation
  └── Integration tests, end-to-end validation, documentation
```

## Complexity Tracking

> **Deviations from Constitution requiring justification**

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| APScheduler instead of Dapr Jobs API (Principle II deviation) | Dapr Jobs API has no Python SDK support as of 2026-02. APScheduler runs in-process. | K8s CronJobs: 1-min minimum granularity, cannot create schedules dynamically at runtime. Raw HTTP to Dapr Jobs API: fragile, no error handling, no SDK type safety. |
| K8s YAML instead of Helm charts (Phase 4 used Helm) | Dapr annotations handle sidecar injection and component binding, replacing Helm's templating value. 5 services with identical patterns do not benefit from Helm's parameterization overhead. | Helm: adds template complexity without proportional benefit when Dapr handles the variability. |
